{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create `voc_sources.csv`\n",
    "\n",
    "This notebook transforms the original VOC pay ledger (soldijboeken) file from the [VOC Opvarenden collection of the Dutch National Archives](https://www.nationaalarchief.nl/onderzoeken/index/nt00444) into a file with English column names and an additional column with normalized source type information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Reload the Jupyter notebook extensions and import the pandas library for data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preview Data\n",
    "\n",
    "Load the pay ledger data, add English column names using a helper function (`helper.py`), and preview the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "\n",
    "df = helper.read_voyages_df()\n",
    "\n",
    "print(f'Pay ledger data\\n\\tnumber of rows: {df.shape[0]}\\n\\tnumber of columns: {df.shape[1]}')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning - Drop Specific Voyage\n",
    "\n",
    "Drop the voyage number 1662.0 as it lacks necessary information and cannot be mapped to the Dutch-Asiatic Shipping database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.das_voyage_num != '1662.0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Voyage Numbers\n",
    "\n",
    "Restore leading zeros dropped in voyage numbers and correct any typos in the voyage numbers using a helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['das_voyage_num'] = df.das_voyage_num.apply(helper.add_voyage_number_leading_zeros)\n",
    "# show that the leading zeros are restored\n",
    "df[df.das_voyage_num == '0973.1']\n",
    "\n",
    "from helper import voyage_num_map_str\n",
    "\n",
    "df['das_voyage_num'] = df.das_voyage_num.apply(lambda x: voyage_num_map_str[x] if x in voyage_num_map_str else x)\n",
    "\n",
    "# listing rows with das voyage number 0496.2 should give no results, 0496.1 should give one result\n",
    "df[df.das_voyage_num.isin(['0496.2', '0496.1'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Source Type and Clean Chamber Information\n",
    "\n",
    "Introduce a new column `source_type` and refine the chamber field based on specific criteria for records associated with 'Regiment', 'Verzoekboeken', or other types.\n",
    "\n",
    "This involves setting `source_type` to `regiment_book` for 'Regiment' records, to `request_book` for 'Verzoekboeken', and defaulting to `pay_ledger` for all others. The label Verzoekboeken is removed from the chamber name, and the chamber field is left blank for 'Regiment' records, indicating no chamber designation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.chamber.value_counts()\n",
    "\n",
    "#add source type\n",
    "from helper import get_source_type\n",
    "\n",
    "df['source_type'] = df.chamber.apply(get_source_type)\n",
    "df.source_type.value_counts()\n",
    "\n",
    "#clean chamber field\n",
    "df['chamber'] = df.chamber.apply(lambda x: x.replace('Verzoekboeken',''))\n",
    "df['chamber'] = df.chamber.apply(lambda x: None if 'Regiment' in x else x)\n",
    "df.chamber.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Voyage Number by DAS Voyage ID\n",
    "\n",
    "Continue with steps to replace the voyage number with the DAS voyage ID and further data processing and cleaning.\n",
    "\n",
    "This is needed as the voyage number is not in fact a number: some voyages have a suffix like 'a' or 'b'. A better alternative is the DAS Voyage ID from the [Dutch-Asiatic Shipping (DAS) database](https://resources.huygens.knaw.nl/das/). This is a proper running number, and is therefore easier to process in various applications. For voyages that do not appear in the DAS dataset, a placeholder voyage ID is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve the DAS Voyage ID from the DAS dataset (which can be found in the `external` folder).\n",
    "das_file = '../external/das.xlsx'\n",
    "das_df = pd.read_excel(das_file, engine='openpyxl', dtype={'voyId': int, 'voyNumberDAS': 'string'})\n",
    "das_df.head(3)\n",
    "\n",
    "#Rename the column `voyId` into `das_voyage_id`, and `voyNumberDAS` into `das_voyage_num`.\n",
    "das_df = das_df[['voyId', 'voyNumberDAS']]\n",
    "das_df.rename(columns={'voyId': 'das_voyage_id', 'voyNumberDAS': 'das_voyage_num'}, inplace=True)\n",
    "das_df\n",
    "\n",
    "#Merge the `das_voyage_id` into the original data frame.\n",
    "merged_df = pd.merge(df, das_df, on='das_voyage_num', how='left')\n",
    "merged_df\n",
    "\n",
    "#Add a value in `das_voyage_id` for voyages that do not appear in the DAS dataset.\n",
    "def fill_missing_voyage_ids(voyage_row):\n",
    "    num_id_map = {\n",
    "        '0000.0': 0,\n",
    "        '4800.1': 100001,\n",
    "        '4801.1': 100002,\n",
    "    }\n",
    "    if voyage_row['das_voyage_num'] in num_id_map:\n",
    "        return num_id_map[voyage_row['das_voyage_num']]\n",
    "    elif isinstance(voyage_row['das_voyage_num'], str):\n",
    "        return voyage_row['das_voyage_id']\n",
    "    else:\n",
    "        return 100003\n",
    "\n",
    "merged_df['das_voyage_id'] = merged_df.apply(fill_missing_voyage_ids, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize Dataset\n",
    "\n",
    "Remove unused columns and write the dataframe to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['das_voyage_id'] = merged_df.das_voyage_id.astype(int)\n",
    "\n",
    "#Remove unused columns.\n",
    "processed_headers = [\n",
    "    'source_id',\n",
    "    'ship_name',      \n",
    "    'chamber',\n",
    "    'source_type',\n",
    "    'das_voyage_id',\n",
    "    'remarks',\n",
    "    'archival_reference',\n",
    "    'uid'\n",
    "]\n",
    "\n",
    "drop_columns = [column for column in merged_df.columns if column not in processed_headers]\n",
    "merged_df = merged_df.drop(drop_columns, axis=1)\n",
    "\n",
    "processed_file = '../enriched/voc_sources.csv'\n",
    "\n",
    "merged_df.to_csv(processed_file, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
